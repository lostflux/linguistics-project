{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CS-72: Accelerated Computational Linguistics\n",
        "\n",
        "## Final Project Code\n",
        "\n",
        "### Emotion Detection in Audio\n",
        "\n",
        "### Team Members:\n",
        "\n",
        "- Aiwei Zhang\n",
        "- Amittai Siavava\n",
        "- Carlos Guerrero Alvarez\n",
        "\n",
        "> This is a variant of our model that uses Wav2Vec features extracted from audio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYgIn9dcBPmf",
        "outputId": "712294b1-53f7-4d12-8de8-d5ccdc12954e"
      },
      "outputs": [],
      "source": [
        "# %pip install pytorch_lightning\n",
        "# %pip install transformers\n",
        "# %pip install torchmetrics\n",
        "# %pip install soundfile\n",
        "# %pip install librosa\n",
        "# %pip install ipywidgets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TuOzAxpATzY1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3/dist-packages/pkg_resources/__init__.py:116: PkgResourcesDeprecationWarning: 1.12.1-git20200711.33e2d80-dfsg1-0.6 is an invalid version and will not be supported in a future release\n",
            "  warnings.warn(\n",
            "/usr/lib/python3/dist-packages/pkg_resources/__init__.py:116: PkgResourcesDeprecationWarning: 1.12.1-git20200711.33e2d80-dfsg1-0.6 is an invalid version and will not be supported in a future release\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import math\n",
        "import pytorch_lightning as pl\n",
        "# import torchaudio\n",
        "import torchmetrics\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nT7lBemwZWm2",
        "outputId": "ba42628d-f940-4527-bc92-6991ce7a20a3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from local_dataset import AudioEmotionsDataset \n",
        "# import TQDMProgressBar\n",
        "from pytorch_lightning.callbacks import TQDMProgressBar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
            "2024-03-12 18:25:01.408103: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-03-12 18:25:01.451361: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX512F AVX512_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 32\n",
        "# dataset = AudioEmotionsDataset(\"data/audio-emotions\", batch_size=BATCH_SIZE)\n",
        "dataset = AudioEmotionsDataset(\"/home/ubuntu/siavava-west-1/test/data/audio-emotions\", batch_size=BATCH_SIZE, max_size=200, feature_type=\"wav2vec\")\n",
        "\n",
        "train = dataset.train_dataloader\n",
        "test = dataset.test_dataloader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "xytqEb8a_1Vi"
      },
      "outputs": [],
      "source": [
        "class SpeechEmotionRecognitionModel(pl.LightningModule):\n",
        "    def __init__(self, input_size, num_classes, dim_feedforward=2048, dim_model=1024, nhead=8, num_encoder_layers=6, num_decoder_layers=6, lr=1e-2, dropout=0.1):\n",
        "        super(SpeechEmotionRecognitionModel, self).__init__()\n",
        "        self.lr = lr\n",
        "\n",
        "        encoder_layers = nn.TransformerEncoderLayer(dim_model, nhead, dim_feedforward, dropout)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_encoder_layers)\n",
        "        self.encoder = nn.Linear(input_size, dim_model)\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(dim_model, num_classes),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "        \n",
        "        self.loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "        # initialize the metrics\n",
        "        self.precision = torchmetrics.Precision(task='multiclass', num_classes=num_classes, average=\"macro\")\n",
        "        self.recall = torchmetrics.Recall(task='multiclass', num_classes=num_classes, average=\"macro\")\n",
        "        self.F1 = torchmetrics.F1Score(task='multiclass', num_classes=num_classes, average=\"macro\")\n",
        "\n",
        "    def forward(self, src):\n",
        "        src = self.encoder(src)\n",
        "        # print(f\"{src.shape = }\")\n",
        "        # src = src.unsqueeze(1)  # Add batch dimension\n",
        "        output = self.transformer_encoder(src)\n",
        "        output = output.squeeze(1)  # Remove the batch dimension\n",
        "        output = self.decoder(output)\n",
        "        return output\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        src, tgt = batch[0], batch[1]\n",
        "        output = self(src)\n",
        "        loss = self.loss_function(output, tgt)\n",
        "        self.log('cross entropy loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        src, tgt = batch\n",
        "        output = self(src)\n",
        "        loss = self.loss_function(output, tgt.float())\n",
        "        self.log('cross entropy loss', loss, on_epoch=True, prog_bar=True)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
        "        scheduler = {\n",
        "            'scheduler': ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, verbose=True),\n",
        "            'monitor': 'cross entropy loss_epoch',  # Name of the metric to monitor\n",
        "            'interval': 'epoch',\n",
        "            'frequency': 1,\n",
        "        }\n",
        "        return {'optimizer': optimizer, 'lr_scheduler': scheduler}\n",
        "\n",
        "    # function for evaluating the quality of output and target\n",
        "    def evaluation(self, output, target, loss):\n",
        "\n",
        "        precision = self.precision(output, target)\n",
        "        recall = self.recall(output, target)\n",
        "        f1 = self.F1(output, target)\n",
        "\n",
        "        print(f\"CE:        {loss}\")\n",
        "        print(f\"PRECISION: {precision}\")\n",
        "        print(f\"RECALL:    {recall}\")\n",
        "        print(f\"F1:        {f1}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Create Model and Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n"
          ]
        }
      ],
      "source": [
        "model = SpeechEmotionRecognitionModel(input_size=dataset.feature_count, num_classes=dataset.class_count)\n",
        "\n",
        "for p in model.parameters():\n",
        "    if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)\n",
        "\n",
        "trainer = pl.Trainer(default_root_dir='checkpoints',callbacks=[TQDMProgressBar(refresh_rate=10)], accelerator=\"auto\", max_epochs=50, min_epochs=10, log_every_n_steps=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Sample Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Train The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name                | Type                | Params\n",
            "------------------------------------------------------------\n",
            "0 | transformer_encoder | TransformerEncoder  | 50.4 M\n",
            "1 | encoder             | Linear              | 102 M \n",
            "2 | decoder             | Sequential          | 7.2 K \n",
            "3 | loss_function       | CrossEntropyLoss    | 0     \n",
            "4 | precision           | MulticlassPrecision | 0     \n",
            "5 | recall              | MulticlassRecall    | 0     \n",
            "6 | F1                  | MulticlassF1Score   | 0     \n",
            "------------------------------------------------------------\n",
            "152 M     Trainable params\n",
            "0         Non-trainable params\n",
            "152 M     Total params\n",
            "610.718   Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cccfb1c1a3f6410fab02e792d42d799c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea3d8c443c1a4f578adcfbe35b576871",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4dee4d587c0c46b9b42d95f506426c76",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "29f68dc9959845219ca713005c8a8655",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "adabe857dc244d5fa6d72be235eab9e7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b479f9ace9f44f4ea666733872d3a608",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "53bcfc72e0f1433f997100576838e2fe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 00005: reducing learning rate of group 0 to 1.0000e-03.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "708c895f3747465f8946e6b473f022bb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "02193aaad52c4dfb9486851ab6f7fc37",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cc8c76e8974441dda0af10f424b75f69",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 00008: reducing learning rate of group 0 to 1.0000e-04.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f1c2e44c4b0c4b84a64c47ecb4aa4fe7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e53762dc0b564dbf8b9dab59d10f5666",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "96bb1eea7aac4aacae8b13197bd57d81",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 00011: reducing learning rate of group 0 to 1.0000e-05.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "37162bded457451ca94f709b85774403",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "39d589f68432442f89d29b7dc500e78a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ec7b77ce304c4f8b8fa18165b76cac74",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 00014: reducing learning rate of group 0 to 1.0000e-06.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9a6723a41af54072910be670f01d37ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d5cf6923dc074b51b260625fef83fe83",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "936af51d84d1490b84021920996e747f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 00017: reducing learning rate of group 0 to 1.0000e-07.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "19c02c20585c4a598ac8ad99af7ba98f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c6825d262624989b345f92cc8c07a76",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "493a7dcc162a4fe9bd39bf56d93319a5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 00020: reducing learning rate of group 0 to 1.0000e-08.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "12313c28adba45b6bc96d82c89e8331c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f980d20a2f4141e98131831dab8608c3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer.fit(model, train_dataloaders=train, val_dataloaders=test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Sample Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X: torch.Size([32, 99875])\n",
            "y: torch.Size([32, 7])\n",
            "output: torch.Size([32, 7])\n",
            "CE:        1.9527029991149902\n",
            "PRECISION: 0.4285714328289032\n",
            "RECALL:    0.5\n",
            "F1:        0.4615384638309479\n"
          ]
        }
      ],
      "source": [
        "for batch in test:\n",
        "    X, y = batch\n",
        "    X = X.cuda(0)\n",
        "    y = y.cuda(0)\n",
        "    model = model.cuda(0)\n",
        "    print(f\"X: {X.shape}\")\n",
        "    print(f\"y: {y.shape}\")\n",
        "    # print(f\"model: {model.device}\")\n",
        "\n",
        "    output = model(X)\n",
        "    print(f\"output: {output.shape}\")\n",
        "    model.evaluation(output, y, model.loss_function(output, y))\n",
        "\n",
        "\n",
        "    # for i in range(32):\n",
        "    #     print(f\"{torch.argmax(output[i]):2d} | {torch.argmax(y[i]):2d} with {torch.max(output[i]):.2f}\")\n",
        "    break"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
