{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYgIn9dcBPmf",
        "outputId": "712294b1-53f7-4d12-8de8-d5ccdc12954e"
      },
      "outputs": [],
      "source": [
        "# %pip install pytorch_lightning\n",
        "# %pip install transformers\n",
        "# %pip install torchmetrics\n",
        "# %pip install soundfile\n",
        "# %pip install librosa\n",
        "# %pip install ipywidgets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TuOzAxpATzY1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3/dist-packages/pkg_resources/__init__.py:116: PkgResourcesDeprecationWarning: 1.12.1-git20200711.33e2d80-dfsg1-0.6 is an invalid version and will not be supported in a future release\n",
            "  warnings.warn(\n",
            "/usr/lib/python3/dist-packages/pkg_resources/__init__.py:116: PkgResourcesDeprecationWarning: 1.12.1-git20200711.33e2d80-dfsg1-0.6 is an invalid version and will not be supported in a future release\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "# import math\n",
        "import pytorch_lightning as pl\n",
        "# import torchaudio\n",
        "import torchmetrics\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nT7lBemwZWm2",
        "outputId": "ba42628d-f940-4527-bc92-6991ce7a20a3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from local_dataset import AudioEmotionsDataset \n",
        "# import TQDMProgressBar\n",
        "from pytorch_lightning.callbacks import TQDMProgressBar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LOADED: 2400\r"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 32\n",
        "dataset = AudioEmotionsDataset(\"/home/ubuntu/siavava-west-1/test/data/audio-emotions\", batch_size=BATCH_SIZE, max_size=200, feature_type=\"mfcc\")\n",
        "\n",
        "train = dataset.train_dataloader\n",
        "test = dataset.test_dataloader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # visualize one fetures 2D array using matplotlib\n",
        "# import matplotlib.pyplot as plt\n",
        "# import numpy as np\n",
        "# import librosa.display\n",
        "\n",
        "# # %pip install resampy\n",
        "\n",
        "# def extract_mfcc_features(file: str):\n",
        "#     \"\"\"\n",
        "#         Loads audio from a given file path and extracts features using the MFCC algorithm.\n",
        "#     \"\"\"\n",
        "    \n",
        "#     # NOTE: resample to 16kHz\n",
        "#     waveform, sample_rate = librosa.load(file, res_type='kaiser_fast')\n",
        "#     # mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
        "    \n",
        "#     #? extract features\n",
        "#     features = librosa.feature.mfcc(y=waveform, sr=sample_rate, n_mfcc=40)\n",
        "\n",
        "#     print(f\"{features.shape = }\")\n",
        "\n",
        "#     features = torch.mean(torch.tensor(features), axis=1)\n",
        "\n",
        "#     print(f\"{features.shape = }\")\n",
        "\n",
        "#     features = torch.tensor(features)\n",
        "\n",
        "#     # m = nn.ZeroPad2d((0, 128 - features.shape[1]))\n",
        "    \n",
        "#     # features = m(features)[:, :128]\n",
        "\n",
        "#     # # trim any excess to (128, 128)\n",
        "#     # features = features[:, :128]\n",
        "#     # features = torch.mean(features, axis=1)\n",
        "\n",
        "#     # print(f\"{features = }\")\n",
        "\n",
        "#     # print(f\"{features.shape = }\")\n",
        "#     # features = features.unsqueeze(1)\n",
        "#     # print(f\"{features.shape = }\")\n",
        "    \n",
        "#     return waveform, features\n",
        "\n",
        "# files = [\n",
        "#       \"/home/ubuntu/siavava-west-1/test/data/audio-emotions/Angry/03-01-05-01-01-01-01.wav\"\n",
        "#     , \"/home/ubuntu/siavava-west-1/test/data/audio-emotions/Disgusted/03-01-07-01-01-01-02.wav\"\n",
        "#     , \"/home/ubuntu/siavava-west-1/test/data/audio-emotions/Fearful/03-01-06-01-01-01-01.wav\"\n",
        "#     , \"/home/ubuntu/siavava-west-1/test/data/audio-emotions/Happy/03-01-03-01-01-01-01.wav\"\n",
        "#     , \"/home/ubuntu/siavava-west-1/test/data/audio-emotions/Neutral/03-01-01-01-01-01-02.wav\"\n",
        "#     , \"/home/ubuntu/siavava-west-1/test/data/audio-emotions/Sad/03-01-04-01-01-01-01.wav\"\n",
        "#     , \"/home/ubuntu/siavava-west-1/test/data/audio-emotions/Surprised/03-01-08-01-01-01-01.wav\"\n",
        "# ]\n",
        "\n",
        "# # get one batch of data\n",
        "# # for file in files:\n",
        "# #     waveform, features = extract_mfcc_features(file)\n",
        "# #     print(f\"{features.shape = }\")\n",
        "# #     plt.figure(figsize=(10, 4))\n",
        "# #     librosa.display.specshow(features.numpy(), x_axis='time')\n",
        "# #     plt.colorbar()\n",
        "# #     plt.title(f\"MFCC - {file.split('/')[2]}\")\n",
        "# #     plt.tight_layout()\n",
        "# #     plt.show()\n",
        "# # _, x = extract_mfcc_features(\"data/audio-emotions/Angry/03-01-05-01-01-01-01.wav\")\n",
        "# # # x, y = batch\n",
        "# # print(x.shape)\n",
        "# # plt.figure(figsize=(10, 4))\n",
        "# # librosa.display.specshow(x[:10].numpy(), x_axis='time')\n",
        "# # plt.colorbar()\n",
        "# # plt.title('MFCC')\n",
        "# # plt.tight_layout()\n",
        "# # plt.show()\n",
        "# # break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X.shape = torch.Size([32, 40])\n",
            "0 torch.Size([32, 7, 1])\n",
            "1 torch.Size([32, 7, 1])\n",
            "2 torch.Size([32, 7, 1])\n",
            "3 torch.Size([32, 7])\n",
            "4 torch.Size([32, 7])\n",
            "5 torch.Size([32, 7])\n"
          ]
        }
      ],
      "source": [
        "m1 = nn.Conv1d(in_channels=1, kernel_size=40, out_channels=7)\n",
        "\n",
        "m2 = nn.ReLU()\n",
        "\n",
        "m3 = nn.Dropout(p=0.2)\n",
        "\n",
        "m4 = nn.Flatten(start_dim=1, end_dim=2)\n",
        "\n",
        "m5 = nn.Linear(2304, 7)\n",
        "\n",
        "m6 = nn.Softmax(dim=1)\n",
        "\n",
        "\n",
        "# m2 = nn.Linear(64, 7)\n",
        "\n",
        "# m2 = nn.Linear(7, 7)\n",
        "\n",
        "\n",
        "# m4 = nn.Linear(7, 7)\n",
        "\n",
        "m5 = nn.Softmax(dim=1)\n",
        "\n",
        "# m6 = nn.Softmax(dim=1)\n",
        "\n",
        "# m1 = nn.Conv1d(in_channels=1, out_channels=40, padding=\"same\")\n",
        "\n",
        "# m2 = nn.ReLU()\n",
        "\n",
        "# m3 = nn.Dropout(p=0.2)\n",
        "\n",
        "# m4 = nn.Flatten()\n",
        "\n",
        "# m5 = nn.Linear(5, 7)\n",
        "\n",
        "# m6 = nn.Softmax(dim=1)\n",
        "\n",
        "# weighted average\n",
        "# w = nn.Parameter(torch.randn(1024, 1))\n",
        "\n",
        "for batch in train:\n",
        "    X, y = batch\n",
        "    # print(f\"{X}\")\n",
        "    # print(X[0], \"\\n\", X.shape)\n",
        "    # X = X.unsqueeze(1)\n",
        "    # print(X[0], \"\\n\", X.shape)\n",
        "\n",
        "    print(f\"{X.shape = }\")\n",
        "\n",
        "    X = X.view(X.shape[0], 1, X.shape[1])\n",
        "\n",
        "    for i, layer in enumerate([m1, m2, m3, m4, m5, m6]):\n",
        "        X = layer(X)\n",
        "        print(i, X.shape)\n",
        "    \n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "xytqEb8a_1Vi"
      },
      "outputs": [],
      "source": [
        "class Reshape(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Reshape, self).__init__()\n",
        "        # self.shape = shape\n",
        "\n",
        "    def forward(self, x):\n",
        "        # return x.view((x.shape[0], *self.shape))\n",
        "        return x.view(x.shape[0], 1, x.shape[1])\n",
        "    \n",
        "    def __call__(self, x):\n",
        "        return self.forward(x)\n",
        "    \n",
        "class Squeeze(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Squeeze, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x.squeeze()\n",
        "    \n",
        "    def __call__(self, x):\n",
        "        return self.forward(x)\n",
        "\n",
        "class Print(nn.Module):\n",
        "    def __init__(self, name: int=0):\n",
        "        super(Print, self).__init__()\n",
        "        self.name = name\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(f\"{self.name:2d}: {x.shape}\")\n",
        "        return x\n",
        "    \n",
        "    def __call__(self, x):\n",
        "        return self.forward(x)\n",
        "    \n",
        "\n",
        "\n",
        "class SpeechEmotionRecognitionModel(pl.LightningModule):\n",
        "    def __init__(self, input_size, num_classes, dim_feedforward=2048, dim_model=1024, nhead=8, num_encoder_layers=6, num_decoder_layers=6, lr=0.5, dropout=0.1):\n",
        "        super(SpeechEmotionRecognitionModel, self).__init__()\n",
        "        self.lr = lr\n",
        "\n",
        "        # encoder_layers = nn.TransformerEncoderLayer(dim_model, nhead, dim_feedforward, dropout)\n",
        "        # self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_encoder_layers)\n",
        "        # self.encoder = nn.Linear(input_size, dim_model)\n",
        "        # self.decoder = nn.Linear(dim_model, num_classes)\n",
        "\n",
        "        # self.layers = nn.Sequential(\n",
        "        #     # nn.Conv1d(in_channels=13, kernel_size=11, out_channels=7),\n",
        "        #     nn.Linear(input_size, 64),\n",
        "        #     nn.Linear(64, 7),\n",
        "        #     nn.Dropout(p=0.1),\n",
        "        #     nn.Linear(7, 7),\n",
        "        #     nn.ReLU(),\n",
        "        #     nn.Linear(7, 7),\n",
        "        #     # nn.Softmax(dim=1),\n",
        "        #     # nn.Sigmoid(),\n",
        "        #     nn.Softmax(dim=1)\n",
        "        # )\n",
        "\n",
        "        self.layers = nn.Sequential(\n",
        "            Reshape(),\n",
        "            nn.Conv1d(in_channels=1, kernel_size=40, out_channels=7),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.2),\n",
        "            nn.Flatten(start_dim=1, end_dim=2),\n",
        "            nn.Linear(7, 7),\n",
        "            # nn.Softmax(dim=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        \n",
        "\n",
        "        # initialize the metrics\n",
        "        self.loss_function = nn.CrossEntropyLoss()\n",
        "        self.precision = torchmetrics.Precision(task='multiclass', num_classes=num_classes, average=\"macro\")\n",
        "        self.recall = torchmetrics.Recall(task='multiclass', num_classes=num_classes, average=\"macro\")\n",
        "        self.F1 = torchmetrics.F1Score(task='multiclass', num_classes=num_classes, average=\"macro\")\n",
        "\n",
        "    def forward(self, src):\n",
        "        output = self.layers(src)\n",
        "        return output\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        src, tgt = batch\n",
        "        \n",
        "        # src = src.unsqueeze(1)\n",
        "        # print(f\"{src.shape = }\")\n",
        "        output = self(src)\n",
        "\n",
        "        # print(f\"{output.shape = }\")\n",
        "        # print(f\"{tgt.shape = }\")\n",
        "        # loss = self.loss_function(output, tgt)\n",
        "        loss = self.loss_function(output, torch.argmax(tgt, axis=1))\n",
        "        self.log('cross entropy loss_step', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        src, tgt = batch\n",
        "        output = self(src)\n",
        "        loss = self.loss_function(output, torch.argmax(tgt, axis=1))\n",
        "        # self.log('cross entropy loss', loss, on_epoch=True, prog_bar=True)\n",
        "        # print(f\"LOSS: {loss}\")\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
        "        scheduler = {\n",
        "            'scheduler': ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, verbose=True),\n",
        "            'monitor': 'cross entropy loss_step',  # Name of the metric to monitor\n",
        "            'interval': 'epoch',\n",
        "            'frequency': 1,\n",
        "        }\n",
        "        return {'optimizer': optimizer, 'lr_scheduler': scheduler}\n",
        "\n",
        "    # function for evaluating the quality of output and target\n",
        "    def evaluation(self, output, target, loss):\n",
        "        # Calculate and log metrics\n",
        "        # output = output.squeeze()\n",
        "\n",
        "        precision = self.precision(output, target)\n",
        "        recall = self.recall(output, target)\n",
        "        f1 = self.F1(output, target)\n",
        "        # print('precision:{}'.format(self.precision(output, target)))\n",
        "        # self.log('recall:{}'.format(self.recall(output, target)))\n",
        "        # self.log('f1:{}'.format(self.F1(output, target)))\n",
        "\n",
        "        print(f\"CE:        {loss}\")\n",
        "        print(f\"PRECISION: {precision}\")\n",
        "        print(f\"RECALL:    {recall}\")\n",
        "        print(f\"F1:        {f1}\")\n",
        "\n",
        "        # self.log('precision', precision)\n",
        "        # self.log('recall', recall)\n",
        "        # self.log('f1', f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n"
          ]
        }
      ],
      "source": [
        "model = SpeechEmotionRecognitionModel(input_size=dataset.feature_count, num_classes=dataset.class_count)\n",
        "\n",
        "for p in model.parameters():\n",
        "    if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)\n",
        "# callbacks=[TQDMProgressBar(refresh_rate=10)]\n",
        "trainer = pl.Trainer(default_root_dir='checkpoints', accelerator=\"auto\", max_epochs=50, min_epochs=2, log_every_n_steps=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X: cuda:0\n",
            "y: cuda:0\n",
            "model: cuda:0\n",
            "output: cuda:0\n",
            "CE:        1.814352035522461\n",
            "PRECISION: 0.5845528244972229\n",
            "RECALL:    0.6354166269302368\n",
            "F1:        0.5896433591842651\n",
            " 1 |  5 >>> 1.00\n",
            " 1 |  3 >>> 1.00\n",
            " 1 |  5 >>> 1.00\n",
            " 1 |  0 >>> 1.00\n",
            " 1 |  4 >>> 1.00\n",
            " 1 |  2 >>> 1.00\n",
            " 1 |  2 >>> 1.00\n",
            " 1 |  5 >>> 1.00\n",
            " 1 |  2 >>> 1.00\n",
            " 1 |  1 >>> 1.00\n",
            " 1 |  5 >>> 1.00\n",
            " 1 |  1 >>> 1.00\n",
            " 1 |  1 >>> 1.00\n",
            " 1 |  5 >>> 1.00\n",
            " 1 |  5 >>> 1.00\n",
            " 1 |  1 >>> 1.00\n",
            " 1 |  4 >>> 1.00\n",
            " 1 |  4 >>> 1.00\n",
            " 1 |  0 >>> 1.00\n",
            " 1 |  1 >>> 1.00\n",
            " 1 |  2 >>> 1.00\n",
            " 1 |  1 >>> 1.00\n",
            " 1 |  1 >>> 1.00\n",
            " 1 |  2 >>> 1.00\n",
            " 1 |  2 >>> 1.00\n",
            " 1 |  5 >>> 1.00\n",
            " 1 |  1 >>> 1.00\n",
            " 1 |  1 >>> 1.00\n",
            " 1 |  4 >>> 1.00\n",
            " 1 |  5 >>> 1.00\n",
            " 1 |  1 >>> 1.00\n",
            " 1 |  5 >>> 1.00\n"
          ]
        }
      ],
      "source": [
        "for batch in test:\n",
        "    X, y = batch\n",
        "    X = X.cuda(0)\n",
        "    y = y.cuda(0)\n",
        "    print(f\"X: {X.device}\")\n",
        "    print(f\"y: {y.device}\")\n",
        "    print(f\"model: {model.device}\")\n",
        "\n",
        "    model = model.cuda(0)\n",
        "    output = model(X)\n",
        "    # print out put device\n",
        "    print(f\"output: {X.device}\")\n",
        "    model.evaluation(output, y, model.loss_function(output, y))\n",
        "\n",
        "    # print(f\"\\n\\nACTUAL\")\n",
        "    # print(y)\n",
        "\n",
        "    # print the predictions\n",
        "    # print(f\"\\n\\nPredictions: {torch.argmax(output, dim=1)}\")\n",
        "    # # print sums of predictions\n",
        "    # print(f\"Predictions sum: {torch.sum(output, dim=1)}\")\n",
        "    # print(output)\n",
        "\n",
        "    for i in range(32):\n",
        "        print(f\"{torch.argmax(output[i]):2d} | {torch.argmax(y[i]):2d} >>> {torch.max(output[i]):.2f}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name          | Type                | Params\n",
            "------------------------------------------------------\n",
            "0 | layers        | Sequential          | 343   \n",
            "1 | loss_function | CrossEntropyLoss    | 0     \n",
            "2 | precision     | MulticlassPrecision | 0     \n",
            "3 | recall        | MulticlassRecall    | 0     \n",
            "4 | F1            | MulticlassF1Score   | 0     \n",
            "------------------------------------------------------\n",
            "343       Trainable params\n",
            "0         Non-trainable params\n",
            "343       Total params\n",
            "0.001     Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "156ab4be47b7420bab093f9d98e1f106",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ubuntu/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:492: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "544398d4e47a4b439efe77ac35fb2fb0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3cdb6cf2832b4ca18e94d540bfb3d28c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c556f3a335e427f94c8ce3ae67a46d6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3b0297aec2524544a207dde0b8847e0f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "889db94d18684ac9aee2bf345b533d03",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a98b8a9377ab4ede907ab2b7aa49c9f8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "924f77b2054e4f7594393f1d123e6b63",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fc9d0c9856c040e5a0a685e228c69f4b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 00007: reducing learning rate of group 0 to 5.0000e-02.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2dd0941096cf4eb882c581c127f52576",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3b6d19048a94410f964a1994f52afe64",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b52c9c3aa09245ee87d8d540f3d598d2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4558d90c2b63433582b5dc0fd8bad865",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b802e17daa2d4226a4763162e74607a4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 00012: reducing learning rate of group 0 to 5.0000e-03.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "55e69293ea584e08b712a9b9074708fd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3b83ddf378bd429084082c8980630ae1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c1afcbb5c3248729a4a162085fceffc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 00015: reducing learning rate of group 0 to 5.0000e-04.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff5e5fedb14645a590b09758f198d8c7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "89ab502a0fec481fa219b4978b51cf9e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e7af8d37f8d3467f8d8aba488d958a16",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 00018: reducing learning rate of group 0 to 5.0000e-05.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ce83cfaa7c08447292803c42ac8c45e0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4f3558c5071a49ab8f092033fb0b4292",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "913d477903994b5c90f07688afa92221",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 00021: reducing learning rate of group 0 to 5.0000e-06.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e1b38e2e537842849742e2c123e1c9d2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff3232e015864802abdd3b8cfc4e64ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6db0151eb71a4fcfb1b964d8a11ebcf5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 00024: reducing learning rate of group 0 to 5.0000e-07.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "39c2e554166b468b8e5220ec02375662",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "944ba71fc5054937a4b1205fb082a09b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "98f5371778714c3498f58c10602ee7b2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 00027: reducing learning rate of group 0 to 5.0000e-08.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f69934dd97fa411581196273c7aa8e74",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "297f44ac27d04547bbd904e0a233dfc4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2f8a64395d0a4f439e97247be549ea7f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 00030: reducing learning rate of group 0 to 5.0000e-09.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c78cea534634918ae036a6032a09edc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "88bd4c3966b345438cd4b08b00d49bb1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "42ab34f8acc1472c9a82eec3efba3215",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a2f3e45de41a4906b11e05fff3ac17fa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "10de718412c6457398a72e946c109fb7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c16d6792d9864810ade55142ab8b0eeb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5aaca9deceeb4b62802b6d7228942464",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "851db4b6266940918ef008a7e03a30af",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1addd691af07485dab8573bde325e0d2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cc60694937554536905eb83fcec8bbc5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5013903cbf7e47b9abda9bd43bb3bbd9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eb94a74d07cb4568961aa860c222db7e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6201a86599bd4999971e019ed939135c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c400fbf31a6c4a3b80cdf197e9f42598",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5300e8cd3a8e4fc899bcf46d72b29d80",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b9f285e970034ab2b5d4c779db7d1d04",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cb3dbe1319bd4b3e8115cf823f2f9205",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0cb412865b6340b4819e6107d44c080c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c926e6cab7254650b77399a8a1465152",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3acdf0d5b81b44dc8a12c82ed22ba170",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
          ]
        }
      ],
      "source": [
        "torch.set_float32_matmul_precision('medium')\n",
        "trainer.fit(model, train_dataloaders=train, val_dataloaders=test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X: cuda:0\n",
            "y: cuda:0\n",
            "model: cuda:0\n",
            "output: cuda:0\n",
            "CE:        1.8459675312042236\n",
            "PRECISION: 0.5731707215309143\n",
            "RECALL:    0.6171875\n",
            "F1:        0.5759648084640503\n",
            " 1 |  5 >>> 1.00\n",
            "\ttensor([0., 1., 1., 0., 0., 0., 0.], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            " 1 |  1 >>> 1.00\n",
            "\ttensor([0., 1., 1., 0., 0., 0., 0.], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            " 1 |  2 >>> 1.00\n",
            "\ttensor([0., 1., 1., 0., 0., 0., 0.], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            " 1 |  1 >>> 1.00\n",
            "\ttensor([0., 1., 1., 0., 0., 0., 0.], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            " 1 |  2 >>> 1.00\n",
            "\ttensor([0., 1., 1., 0., 0., 0., 0.], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            " 1 |  1 >>> 1.00\n",
            "\ttensor([0., 1., 1., 0., 0., 0., 0.], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            " 1 |  0 >>> 1.00\n",
            "\ttensor([0., 1., 1., 0., 0., 0., 0.], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            " 1 |  1 >>> 1.00\n",
            "\ttensor([0., 1., 1., 0., 0., 0., 0.], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            " 1 |  3 >>> 1.00\n",
            "\ttensor([0., 1., 1., 0., 0., 0., 0.], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            " 1 |  1 >>> 1.00\n",
            "\ttensor([0., 1., 1., 0., 0., 0., 0.], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            " 1 |  0 >>> 1.00\n",
            "\ttensor([0., 1., 1., 0., 0., 0., 0.], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            " 1 |  2 >>> 1.00\n",
            "\ttensor([0., 1., 1., 0., 0., 0., 0.], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            " 1 |  5 >>> 1.00\n",
            "\ttensor([0., 1., 1., 0., 0., 0., 0.], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            " 1 |  0 >>> 1.00\n",
            "\ttensor([0., 1., 1., 0., 0., 0., 0.], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            " 1 |  4 >>> 1.00\n",
            "\ttensor([0., 1., 1., 0., 0., 0., 0.], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            " 1 |  3 >>> 1.00\n",
            "\ttensor([0., 1., 1., 0., 0., 0., 0.], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            " 1 |  2 >>> 1.00\n",
            "\ttensor([0., 1., 1., 0., 0., 0., 0.], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            " 1 |  0 >>> 1.00\n",
            "\ttensor([0., 1., 1., 0., 0., 0., 0.], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            " 1 |  1 >>> 1.00\n",
            "\ttensor([0., 1., 1., 0., 0., 0., 0.], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            " 1 |  4 >>> 1.00\n",
            "\ttensor([0., 1., 1., 0., 0., 0., 0.], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            " 1 |  1 >>> 1.00\n",
            "\ttensor([0., 1., 1., 0., 0., 0., 0.], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            " 1 |  3 >>> 1.00\n",
            "\ttensor([0., 1., 1., 0., 0., 0., 0.], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            " 1 |  3 >>> 1.00\n",
            "\ttensor([9.8494e-01, 9.9671e-01, 9.7945e-01, 9.8320e-01, 9.8388e-01, 9.9316e-01,\n",
            "        2.3329e-04], device='cuda:0', grad_fn=<SelectBackward0>)\n",
            " 1 |  5 >>> 1.00\n",
            "\ttensor([0., 1., 1., 0., 0., 0., 0.], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            " 1 |  3 >>> 1.00\n",
            "\ttensor([9.8494e-01, 9.9671e-01, 9.7945e-01, 9.8320e-01, 9.8388e-01, 9.9316e-01,\n",
            "        2.3329e-04], device='cuda:0', grad_fn=<SelectBackward0>)\n",
            " 1 |  1 >>> 1.00\n",
            "\ttensor([0., 1., 1., 0., 0., 0., 0.], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            " 1 |  3 >>> 1.00\n",
            "\ttensor([0., 1., 1., 0., 0., 0., 0.], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            " 1 |  3 >>> 1.00\n",
            "\ttensor([0., 1., 1., 0., 0., 0., 0.], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            " 1 |  1 >>> 1.00\n",
            "\ttensor([0., 1., 1., 0., 0., 0., 0.], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            " 1 |  4 >>> 1.00\n",
            "\ttensor([0., 1., 1., 0., 0., 0., 0.], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            " 1 |  2 >>> 1.00\n",
            "\ttensor([0., 1., 1., 0., 0., 0., 0.], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n",
            " 1 |  2 >>> 1.00\n",
            "\ttensor([0., 1., 1., 0., 0., 0., 0.], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n"
          ]
        }
      ],
      "source": [
        "for batch in test:\n",
        "    X, y = batch\n",
        "    X = X.cuda(0)\n",
        "    y = y.cuda(0)\n",
        "    print(f\"X: {X.device}\")\n",
        "    print(f\"y: {y.device}\")\n",
        "    print(f\"model: {model.device}\")\n",
        "\n",
        "    model = model.cuda(0)\n",
        "    output = model(X)\n",
        "    # print out put device\n",
        "    print(f\"output: {X.device}\")\n",
        "    model.evaluation(output, y, model.loss_function(output, y))\n",
        "\n",
        "    for i in range(32):\n",
        "        print(f\"{torch.argmax(output[i]):2d} | {torch.argmax(y[i]):2d} >>> {torch.max(output[i]):.2f}\\n\\t{output[i]}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create 'models' directory if nonexistent\n",
        "# import os\n",
        "# if not os.path.exists(\"models\"):\n",
        "#     os.makedirs(\"models\")\n",
        "# # save model weights\n",
        "# torch.save(model.state_dict(), \"./models/model_weights.pth\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
